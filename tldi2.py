# -*- coding: utf-8 -*-
"""TLDI2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12bni9CDx41sZh4vdJMoaJI4-sikVgF8G

# TLDI2: Tea Leave Disease Identifier 2

``` json
{
    "info": {
        "version": "v1.5.0",
        "task": "classification",
        "m": 885
    }
}
```

## Data
Source: [Kaggle](https://www.kaggle.com/datasets/shashwatwork/identifying-disease-in-tea-leafs)

```
kaggle datasets download -d shashwatwork/identifying-disease-in-tea-leafs
```

### Citation
> None

## Importing Dependencies
"""

!pip install split-folders

# Commented out IPython magic to ensure Python compatibility.
try:
    import numpy as np
    import pandas as pd
    import os
    import shutil
    from zipfile import ZipFile
    import zipfile
    import splitfolders
    import random
    import time

    # ANN dependencies
    import tensorflow as tf
    import keras

    from keras import Sequential
    
    from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dense
    from keras.layers import Flatten, ZeroPadding2D, BatchNormalization, Activation
    from keras.layers import Add, Input, Dropout, GlobalAveragePooling2D
    from keras.optimizers import SGD

    from keras.models import Model
    from keras.applications import ResNet152V2

    from tensorflow.keras.utils import load_img
    from tensorflow.keras.utils import img_to_array
    from keras.utils.vis_utils import plot_model

    from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau 

    import matplotlib
    import matplotlib.pyplot as plt
    from IPython.display import display

    matplotlib.style.use("ggplot")
#     %matplotlib inline
#     %config InlineBackend.figure_format = "retina"

    print(f"Using tensorflow v{tf.__version__}")
    print(f"Using keras v{keras.__version__}")
    print(f"Using matplotlib v{matplotlib.__version__}")
except Exception:
    import sys
    exc_type, exc_obj, exc_tb = sys.exc_info()
    raise Exception(f"error on importing dependencies! Error on line: {exc_tb.tb_lineno}")
finally:
    print(f"Success on importing dependencies!")

from google.colab import files


class utils:
    def kaggle(token_path: str, datasets=None, copy=True):
        root_dir = "/root/.kaggle"
        file_name = "kaggle.json"
        file_loc = os.path.join(root_dir, file_name)

        if not os.path.isdir(root_dir):
            os.mkdir(root_dir)

        if copy:
            shutil.copy(token_path, root_dir)
            status = "copied"
        else:
            shutil.move(token_path, root_dir)
            status = "moved"

        os.chmod(file_loc, 600)
        print(f"'kaggle.json' file have been {status} to {file_loc}!")

        if datasets is not None:
            from kaggle.api.kaggle_api_extended import KaggleApi

            api = KaggleApi()
            api.authenticate()

            if type(datasets) == str:
                datasets = [datasets]

            for dataset in datasets:
                api.dataset_download_cli(dataset)

            print(f"\nDataset has been successfully downloaded!")

    def unzip(path: str, output_dir: str, del_src=False):
        with ZipFile(path, "r") as zf:
            zf.extractall(output_dir)

        print(f"'{path}' has been extracted!")

        if del_src:
            os.remove(path)

"""## Getting the Data"""

from google.colab import drive

drive.mount("/content/gdrive")

drivebase = "/content/gdrive/MyDrive"
utils.kaggle(token_path=os.path.join(drivebase, "api_identifiers", "kaggle.json"),
             datasets="shashwatwork/identifying-disease-in-tea-leafs")

utils.unzip(path="/content/identifying-disease-in-tea-leafs.zip", output_dir="/content")

"""## Data Preparation"""

def normalize_dir(parent_dir: str):
    for dir_name in os.listdir(parent_dir):
        new_dir_name = dir_name.replace(" ", "_")
        new_dir_name = new_dir_name.lower()

        os.rename(os.path.join(parent_dir, dir_name), os.path.join(parent_dir, new_dir_name))

def data_count(parent_dir: str, plot=True):
    data_lengths = dict()

    for subdir in os.listdir(parent_dir):
        data_lengths[subdir] = len(os.listdir(os.path.join(parent_dir, subdir)))

    return data_lengths

def img_samples(parent_dir: str, n_samples: int):
    random_images = list()

    for dir in os.listdir(parent_dir):
        dir_images = os.listdir(os.path.join(parent_dir, dir))

        for index in range(n_samples):
            random_images.append(os.path.join(parent_dir, dir, dir_images[random.randint(0, len(dir_images)-1)]))

    return random_images

def display_imgs(image_paths: list, rows: int, cols: int, figsize=(10, 5)):
    fig = plt.figure(figsize=figsize)

    for i in range(1, len(image_paths)+1):
        image = load_img(image_paths[i-1])
        image_array = img_to_array(image)
        class_id = image_paths[i-1].split("/")[3]

        fig.add_subplot(rows, cols, i)
        plt.title(f"{class_id}\n{image_array.shape}")
        plt.imshow(image)

dataset_base = "/content/dataset"
os.rename("/content/tea sickness dataset", dataset_base)

normalize_dir(dataset_base)

count = data_count(dataset_base)
count = pd.DataFrame(count.values(), index=count.keys(), columns=["count"])

display(count)

samples = img_samples(dataset_base, 3)

display_imgs(samples, rows=8, cols=3, figsize=(15, 25))

splitfolders.ratio(
    dataset_base,
    output="main_dataset",
    seed=2345, ratio=(.8, .1, .1),
    move=False
)

dataset_base = os.path.join(os.getcwd(), "main_dataset")

train_dir = os.path.join(dataset_base, "train")
val_dir = os.path.join(dataset_base, "val")
test_dir = os.path.join(dataset_base, "test")

for subdir in os.listdir(test_dir):
    subdir_path = os.path.join(test_dir, subdir)
    images = os.listdir(subdir_path)

    print(subdir)
    
    for index in range(0, len(images)-10):
        image_path = os.path.join(subdir_path, images[index])
        
        print(f"moving image \"{image_path}\"")
        shutil.move(image_path, os.path.join(val_dir, subdir))
        print(f"success!")

"""### Data Preprocessing"""

IMG_SIZE = (224, 224)
INPUT_SHAPE = (224, 224, 3)
TRAIN_BATCH = 128
VAL_BATCH = 128

train = tf.keras.utils.image_dataset_from_directory(
    train_dir,
    seed=321,
    image_size=IMG_SIZE,
    batch_size=TRAIN_BATCH,
    label_mode="categorical"
)

val = tf.keras.utils.image_dataset_from_directory(
    val_dir,
    seed=321,
    image_size=IMG_SIZE,
    batch_size=VAL_BATCH,
    label_mode="categorical"
)

classes = train.class_names
print(classes)

AUTOTUNE = tf.data.AUTOTUNE

train = train.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val = val.cache().prefetch(buffer_size=AUTOTUNE)

"""## Modelling

### Basic Functions (callback and eval)
"""

class LimitTrainingTime(tf.keras.callbacks.Callback):
    def __init__(self, max_time_s):
        super().__init__()
        self.max_time_s = max_time_s
        self.start_time = None

    def on_train_begin(self, logs):
        self.start_time = time.time()

    def on_train_batch_end(self, batch, logs):
        now = time.time()
        if now - self.start_time >  self.max_time_s:
            self.model.stop_training = True

class AccuracyCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
        if(logs.get("categorical_accuracy")>0.9):
            self.model.stop_training = True


early_stopping = tf.keras.callbacks.EarlyStopping(monitor="val_categorical_accuracy", verbose=1, patience=7, mode="auto")
reduce_lr = ReduceLROnPlateau(monitor="val_categorical_accuracy", verbose=1, patience=5, min_lr=0.001)
checkpoint = ModelCheckpoint(filepath="/content", monitor="val_categorical_accuracy", verbose=1, save_best_only=True)

acc_callback = AccuracyCallback()
time_callback = LimitTrainingTime(45*60)

def tldi2_predict(model, test_dir, classes, raw_pred=True, display_img=True):
    clss = os.listdir(test_dir)
    random_class = clss[random.randint(0, len(clss)-1)]
    images = os.listdir(os.path.join(test_dir, random_class))

    random_img = images[random.randint(0, len(images)-1)]
    random_img = os.path.join(test_dir, random_class, random_img)

    loaded_img = load_img(random_img, target_size=(224, 224))

    if display_img:
        plt.figure()
        plt.imshow(loaded_img)
        plt.colorbar()
        plt.grid(False)
        plt.show()

        print("\n")

    loaded_img = img_to_array(loaded_img)
    loaded_img = np.expand_dims(loaded_img, axis=0)

    y_hat = model.predict(np.vstack([loaded_img]))

    if raw_pred:
        print(f"prediction: {y_hat}")

    y_hat_class = classes[np.argmax(y_hat)]

    print(f"true_class: {random_class}",
          f"\nprediction_class: {y_hat_class}",
          f"\n\nreal_img_path: {random_img}")
    
    return (raw_pred, y_hat_class, random_class, random_img)

def zipdir(path, ziph):
    for root, dirs, files in os.walk(path):
        for file in files:
            ziph.write(os.path.join(root, file), 
                       os.path.relpath(os.path.join(root, file), 
                                       os.path.join(path, "..")))

"""## Defining and Training

### Custom CNN Architecture

#### Training
"""

def define_model():
    augmentation = Sequential([
        keras.layers.RandomFlip("horizontal", input_shape=INPUT_SHAPE),
        keras.layers.RandomFlip("vertical"),
        keras.layers.RandomRotation(0.2),
        keras.layers.RandomZoom(0.2)
    ])

    model = Sequential([
        augmentation,
        keras.layers.Rescaling(1./255),
        Conv2D(64, (3, 3), activation="relu", kernel_initializer="he_uniform", padding="same"),
        MaxPooling2D((2, 2)),
        Dropout(0.2),
        Conv2D(64, (3, 3), activation="relu", kernel_initializer="he_uniform", padding="same"),
        MaxPooling2D((2, 2)),
        Dropout(0.2),
        Conv2D(128, (3, 3), activation="relu", kernel_initializer="he_uniform", padding="same"),
        MaxPooling2D((2, 2)),
        Dropout(0.2),
        Conv2D(128, (3, 3), activation="relu", kernel_initializer="he_uniform", padding="same"),
        MaxPooling2D((2, 2)),
        Dropout(0.2),
        Flatten(),
        Dense(64, activation="relu", kernel_initializer="he_uniform"),
        Dropout(0.2),
        Dense(128, activation="relu", kernel_initializer="he_uniform"),
        BatchNormalization(),
        Dense(64, activation="relu", kernel_initializer="he_uniform"),
        Dropout(0.2),
        BatchNormalization(),
        Dense(8, activation="softmax")
    ])

    model.compile(optimizer=tf.keras.optimizers.Adam(0.0005),
                  loss=keras.losses.CategoricalCrossentropy(),
                  metrics=[keras.metrics.CategoricalAccuracy()])
    
    print("\n")
    model.summary()
    print("\n")
    
    plot_model(model, to_file="model_architecture.png", show_shapes=True, show_layer_names=True)

    return model

model_1 = define_model()
history_1 = model_1.fit(train,
                      validation_data=val,
                      epochs=200,
                      verbose=1,
                      callbacks=[checkpoint, acc_callback])

"""#### Quick Eval"""

for i in range(10):
    pred, y_hat, y, img_paths = tldi2_predict(model_1, test_dir, classes)

"""#### Training @2"""

def define_model_g2():
    augmentation = Sequential([
        keras.layers.RandomFlip("horizontal", input_shape=INPUT_SHAPE),
        keras.layers.RandomFlip("vertical"),
        keras.layers.RandomRotation(0.2),
        keras.layers.RandomZoom(0.2)
    ])

    model = Sequential([
        augmentation,
        keras.layers.Rescaling(1./255),
        Conv2D(64, (3, 3), activation="relu", kernel_initializer="he_uniform", padding="same"),
        MaxPooling2D((2, 2)),
        Conv2D(64, (3, 3), activation="relu", kernel_initializer="he_uniform", padding="same"),
        MaxPooling2D((2, 2)),
        Conv2D(128, (3, 3), activation="relu", kernel_initializer="he_uniform", padding="same"),
        MaxPooling2D((2, 2)),
        Conv2D(128, (3, 3), activation="relu", kernel_initializer="he_uniform", padding="same"),
        MaxPooling2D((2, 2)),
        Dropout(0.5),
        Flatten(),
        Dense(64, activation="relu", kernel_initializer="he_uniform"),
        Dense(128, activation="relu", kernel_initializer="he_uniform"),
        BatchNormalization(),
        Dense(64, activation="relu", kernel_initializer="he_uniform"),
        BatchNormalization(),
        Dense(8, activation="softmax")
    ])

    model.compile(optimizer=tf.keras.optimizers.Adam(0.0005),
                  loss=keras.losses.CategoricalCrossentropy(),
                  metrics=[keras.metrics.CategoricalAccuracy()])
    
    print("\n")
    model.summary()
    print("\n")
    
    plot_model(model, to_file="model_architecture@2.png", show_shapes=True, show_layer_names=True)

    return model

model_2 = define_model_g2()
history_2 = model_2.fit(train,
                        validation_data=val,
                        epochs=200,
                        verbose=1,
                        callbacks=[checkpoint, acc_callback])

"""#### Quick Eval @2"""

for i in range(10):
    pred, y_hat, y, img_paths = tldi2_predict(model_2, test_dir, classes)

model_2.save("tldi2_g2.h5")

export_dir = "tldi2v1_g2/"
tf.saved_model.save(model_2, export_dir)

with zipfile.ZipFile("tldi2v1_g2.zip", "w", zipfile.ZIP_DEFLATED) as zipf:
    zipdir(os.path.join(os.getcwd(), export_dir), zipf)

"""### ResNet50 and ResNet152V2 """

def resnet152v2():
    base_model = ResNet152V2(weights="imagenet", include_top=False, input_tensor=Input(shape=(224, 224, 3)))
    base_model.trainable = False

    main_model = Sequential([
        base_model,
        Dropout(0.6),
        Flatten(),
        Dense(256, activation="relu", kernel_initializer="he_uniform"),
        Dense(8, activation="softmax")
    ])
    
    main_model.compile(optimizer=SGD(learning_rate=0.0005), 
                  loss=tf.keras.losses.CategoricalCrossentropy(), 
                  metrics=[tf.keras.metrics.CategoricalAccuracy()])

    print("\n")
    main_model.summary()
    print("\n")
    plot_model(main_model, to_file="model_architecture_resnet152.png", show_shapes=True, show_layer_names=True)

    return main_model

model_3 = resnet152v2()

history_3 = model_3.fit(train,
                        validation_data=val,
                        epochs=200,
                        verbose=1,
                        callbacks=[acc_callback, reduce_lr])

from keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input

def resnet50():
    base_model = ResNet50(weights="imagenet", include_top=False, input_shape=(224, 224, 3), classes=8)
    base_model.trainable = False

    pt = Input(shape=(224, 224, 3))
    func = tf.cast(pt, tf.float32)
    x = preprocess_input(func)

    model = base_model(x, training=False)
    model = GlobalAveragePooling2D()(model)
    model = Dense(256, activation="relu")(model)
    model = Dense(8, activation="softmax")(model)

    main_model = Model(inputs=pt, outputs=model)
    
    main_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), 
                  loss=tf.keras.losses.CategoricalCrossentropy(), 
                  metrics=[tf.keras.metrics.CategoricalAccuracy()])

    print("\n")
    main_model.summary()
    print("\n")
    plot_model(main_model, to_file="model_architecture_resnet.png", show_shapes=True, show_layer_names=True)

    return main_model

class AccuracyCallback50(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
        if(logs.get("categorical_accuracy")>0.99):
            self.model.stop_training = True

resnet50_acc = AccuracyCallback50()

model_4 = resnet50()

history_4 = model_4.fit(train,
                        validation_data=val,
                        epochs=200,
                        verbose=1,
                        callbacks=[resnet50_acc])

"""#### Quick Eval"""

for i in range(10):
    pred, y_hat, y, img_paths = tldi2_predict(model_4, test_dir, classes)

model_4.save("tldi2_resnet50.h5")